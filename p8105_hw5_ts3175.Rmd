---
title: "p8105_hw5_TS3175"
author: "Tanu"
date: "11/7/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1

```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

```{r}
iris_no_missing = function(x) {
    if (is.numeric(x)) {
      replace_na(x, mean(x, na.rm=TRUE))
    }
    else if (is.character(x)) {
       (replace_na(x, "virginica"))}
  }
```

```{r}
output = map(iris_with_missing, iris_no_missing)
```

# Problem 2

Loading data
```{r}
df= 
  tibble(participant = list.files(path = "data/", pattern = "csv", all.files = TRUE, full.names = TRUE)) %>% 
    mutate(df = map(participant, read_csv)) %>% 
    unnest()
```

Cleaning data 
```{r}
df1 =
df %>%
janitor::clean_names() %>% 
  mutate(
    participant= str_remove(participant, "data//"),
    participant= str_remove(participant, ".csv")
  ) %>% 
pivot_longer(
  week_1:week_8,
  names_to= "week",
  names_prefix = "week_",
  values_to = "obs")  
```

```{r}
df2 =
  df1 %>% 
  mutate(
     participant2= participant
  ) %>% 
    separate(participant, into=c("arm", "subject_id"), sep="_"
          ) 
```

Plotting data 
```{r}
df2 %>% 
  ggplot(aes(x= week, y= obs, color= arm, group= participant2)) +
  geom_line() + 
 viridis::scale_color_viridis(
 name = "Subject ID", 
 discrete = TRUE, 
 option = "viridis"
 ) + 
 theme_minimal()
  labs(
    title = "Observations Over Time by Group" ,
      x= "Time (Week)",
      y = "Observation"
  ) 
```

The experimental group had higher observations overtime while the control group experienced about the same observations from begining of the 8 weeks until the end with a slight overall decrese.

# Problem 3

Creating a function
```{r}
set.seed(10)

sim_regression = function(n = 30, beta0 = 2, beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(n),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
    )
  
  ls_fit = lm(y ~ x, data = sim_data) %>% 
    broom::tidy()
  
  tibble(
    be1 = ls_fit[[2, 2]],
    p_value = ls_fit[[2, 5]])

}
```

Generating 10000 datasets from the model above
```{r}
sim_results =
  tibble(
    beta1 = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_list = map(.x = beta1, ~rerun(10000, sim_regression(beta1 = .x))),
         estimate = map(output_list, bind_rows)) %>% 
  select(-output_list) %>% 
  unnest(estimate)
```

Plotting
```{r}
plot1_data=
sim_results %>% 
  group_by(beta1) %>% 
  count(rejected = p_value < 0.05) %>% 
  mutate(proportion = n/sum(n)*100) %>% 
  filter(rejected == TRUE)
```

```{r}
plot1_data %>% 
ggplot(aes(x = beta1, y = proportion)) +
  geom_point() + 
  geom_line() +
  labs(
    title = "The Proportion of Times Null Rejected and True β1",
    x = "True Value of β1",
   y = "Proportion of Times Null Rejected" )
```

The power increased as the value of beta 1 increased. As power increases, the effect size also increases because the effect becomes easier to detect. 

```{r}
plot2_data =
sim_results %>%
  group_by(beta1) %>% 
  mutate(
    avg_est = mean(be1)
  )
```

```{r}
plot3_data =
sim_results %>% 
group_by(beta1) %>% 
filter(p_value <0.05) %>% 
mutate(
    avg_reg = mean(be1)
  )
```

```{r}
ggplot() +
  geom_line(data= plot3_data, (aes(x = beta1, y = avg_reg)), color = "blue") +
  geom_point(data= plot3_data, (aes(x = beta1, y = avg_reg)), color = "blue") +
  geom_line(data= plot2_data, (aes(x = beta1, y = avg_est)), color = "black") +
  geom_point(data= plot2_data, (aes(x = beta1, y = avg_est)), color = "black") +
  labs(
    title = "The Average Estimate of β1 and the True Value of β1",  
    x = "True Value of β1",
    y = "The Average Estimate of β1"
  )
```
The plot above shows the relationship between the average of the beta1 estimates and the true value of beta1. The black line shows this relationship for the whole dataset. The overlayed blue line shows the relationship for a subset of the data in which the null was rejected. The sample average of beta1 estimates for which the null is rejected is slighltly larger than the true value of beta1. This is because, by definition, rejecting the null means that the beta1 estimate of those tests were different enough from the true value of beta1 that it was statistically significant. The plot illustrates this definition because it shows that on average, all of the values, except for when beta1 is 0, is higher in the subset of the data in which the null was rejected.
